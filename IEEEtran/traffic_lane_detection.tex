 \documentclass[conference]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{todonotes}
\usepackage{mathtools}



% correct bad hyphenation here
\usepackage{cite}
\hyphenation{op-tical net-works semi-conduc-tor}

\DeclareUnicodeCharacter{00A0}{~}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Traffic Lane Detection in Urban Environments}


\author{\IEEEauthorblockN{Marin Vlastelica Pogančić}
\IEEEauthorblockA{Karlsruher Institüt für Technologie\\
Karlsruhe, Deutschland\\
Supervisor: Florian Kuhnt}}


% make the title area
\maketitle


\begin{abstract}
%\boldmath
We live in a time of rapid development of autonomous driving systems and the continuous deployment of the same systems in everyday life. This poses a large span of challenges, in order to make the systems reliable and robust in their deployment, much of this robustness relies on the information obtained through sensors from the environment. The pros and cons of different approaches for traffic lane detection will be discussed and the corresponding results compared, with an emphasis on the urban environment, where the challenge of detecting the lanes requires more consideration. 
\end{abstract}



\IEEEpeerreviewmaketitle



\section{Introduction}

As mentioned in the abstract, lane traffic detection in urban environments poses an even greater challenge, there are many reasons for this. One of the main reasons is the cluttered environment, urban environments have many objects, obstacles on the streets which can contribute to the ambiguity of the sensor data. On the other hand, we have many streets in urban environments that don't have lane markings, which means that robust curb detection is also needed to detect the traffic lanes correctly. In chapter II are the lane marking methods discussed. In chapter III are the curb detection methods discussed. 

\subsection{Diverse Approaches}

Diverse solutions for the lane detection problems exist since a long time ago, most of them based on 3D data analysis and pattern recognition. The challenge is to improve the robustness of the detection algorithms using additional context. Therefore, there are some approaches using vehicle tracking to determine the positions of the markings, like proposed in \cite{virtuallane}, that try to use additional context to make the detections more robust and effective. Albeit there are many approaches in this field, the sensor data in use is not so diverse, the driving lane detection is mostly based on stereo-camera imagery and 3D laser sensor data.


\section{Lane Marker Detection}

Lane marker detection is one of the important, if not the most important, challenges in autonomous driving in general. The situation in which the car finds itself will mostly contain environments with traffic lanes denoted by lane markings. Because the environments in which the lanes should be detected are often cluttered, this task is coupled with object detection and prediction methods to make it more efficient. Nowadays the methods for detecting lanes could be divided into two categories: feature-based and model-based methods. The feature-based methods locate the lane-markings using segmentation algorithms whereas the model-based methods use mathematical models to represent the lane. Although the model-base methods achieve impressive results considering their low FPR, they mostly carry high computational costs which unable them to be used in a real-time system.

\subsection{Improved RANSAC Algorithm}

The RANSAC algorithm is the most often used algorithm for lane marking detection. The algorithm is basically an iterative method to estimate parameters of a mathematical model from a set of observed data which contains outliers. In this section will the approach proposed in \cite{ransac} be discussed, which contains a lane marking model-based detection method with an improved RANSAC algorithm.

To achieve a better result in the lane detection step, some image preprocessing is required. The image preprocessing steps that were taken in \cite{ransac} are the following. First of all, a region of interest in the image is chosen. The next preprocessing step is a spatial graying of the image, so the worn out yellow lane markings are better detected. The spatial graying of the image is achieved by 5:4:1 weighted summing of the RGB values, which is proven to be more efficient for determining edges in previous approaches. In addition to the mentioned, a vanishing point of the lanes is added, which can be determined by means of the camera parameters. The last step of the image preprocessing is the denoising of the image. This is achieved by the median filtering method, to meet the real-time requirements.

The most common features used in lane detection are image gradient and edge features. The reason for the preference of these features is their simplicity, which benefits the real-time requirement of the system. Unfortunately these features are also prone to changing lighting conditions. The edge detection algorithm used in this method is the Canny edge detection algorithm.

After the feature extraction part, the next crucial step is lane modelling and lane model parameter estimation. Here comes the trade-off, simple lane models are not able to detect the lanes accurately, for them complex lane shapes (curved lanes) present a problem. On the other hand, the more complex the models are the complexity of the parameter estimation rises and therefore, the computational costs. These points need to be kept in mind when designing a real-time system. For this method, the left and right lane boundaries are described by generalized curves, which has shown good results in the past, in addition, the model takes the planar ground surface and parallel lines constraints.  This model approach is in detail described in \cite{ransac1}. The generalized curve can be described by \ref{eq1}.

\begin{equation}
x = \frac{a}{y-vp_y}+b(y-vp_y) +c
\label{eq1}
\end{equation}

The parameter definitions are as follows: parameter $a$ controls the curvature of the curve, parameter $c$ represents the vanishing point positions, parameter $b$ corresponds to the horizontal positions of the left and right curves - the positions of intersections between the curves and the lowest row of the image, parameter $vp_y$ denotes the vanishing line position in the image and the parameters $x$ and $y$ are the number of the rows and columns of the image. For example, a straight line in the model can be represented when the parameter $a$ is set to 0. 

The parameter estimation of the model is the most important step of the lane detection process, this is where the RANSAC algorithm comes into play, a more detailed explanation of the RANSAC algorithm is available in \cite{ransac2}. The RANSAC algorithm can adapt to the
complex conditions of lane estimation of model parameters
and it does not need training process compared to the Hough
transform and template matching method.

The lane feature points extracted by the Canny method contain a lot of noisy points for various reasons as damaged road surface or varying lighting conditions for example. 

\subsection{Lane Detection Enhancement Using Virtual Lane}

In this section will a method be described, that uses relative movements between the vehicles to enhance the lane detection. This approach is meant to overcome the difficulties that pose themselves through pure detection through the camera. In comparison to the other  



\section{Road Curb Detection}

One of the more important tasks in an urban environment is curb detection. The reason for this is that many streets in an urban environment are small streets without lane markings. In order to fully function in an urban environment, autonomous vehicles have to solve this problem in an appropriate manner also. In this chapter will the different approaches to solving this problem be mentioned.  

\subsection{Elevation Mapping Techniques With Stereo Camera}

In this chapter will an approach suggested in \cite{stereo} be explained. The approach, as the name suggests, is based on using elevation maps. By means of these maps can the most probable paths be calculated. The position accuracy that was able to be achieved is about 10 cm and an height error of about 1.5 cm, tested in real-time.

The sensor used primarily in this approach is the stereo camera, where the output of the stereo camera are two intensity images and one disparity image. For the ego motion is the inertial measurement unit used. 

The first step that is to be made is to take the disparity image and generate a position 3D point cloud from it in the sensor coordinate system. This generated point cloud finds itself in the sensor coordinate system at the beginning, the next step is to transform this point cloud into the map coordinate system after the ground pixels had been detected. Thereafter is important to use the ego motion estimation. 

The ego motion estimation is used to estimate the ego motion of the vehicle between two timestamps. The DEM model used in this approach is based on a 2.5-D map described in \cite{bewegung}. It accumulates of the stereo camera in the Euclidean space using temporal integration. One cell in the map is of the size 20 x 20 cm and has a one dimensional Kalman-Filter which estimates the height of the cell. In each prediction step is the cell height adjusted according to the ego motion of the car, for the correction step is the Kalman-Filter updated with the sensor measurements. 

The detection approach is as follows. The static and dynamic objects lead to value spikes in the DEM, whereby the dynamic objects need to be removed, in order to detect the curbs. The dynamic objects are detected with a laser scanner and removed from the point cloud generated from the stereo camera.The rest of the points are divided into ground points and object points. The ground detection algorithm assumes steadily growing x values in the sensor coordinate system, when the disparity image columns are considered. If the x values are steadily growing, then it can be assumed, that ground is in front of the car, otherwise this assumption cannot be made. To compensate the effect of the outliers, the mean value of two consecutive columns with 3 pixels each is calculated.

What also must be considered are the mapping techniques which also have an effect on the performance, since these are not the central aspect of this paper, all of them are mentioned and analysed in \cite{stereo}. 

The road curb is represented by a polygonal chain, this chain consists of supporting points and the connections between these supporting points. Every point contains a 2D position and the road curb height at its position. 

\subsubsection{Road Curb Detection Algorithm}

The first step at road curb detection is the road curb feature extraction. This is achieved by applying an edge-detection algorithm on the DEM to find cells with a jump in the neighbouring height values, which might be caused by a road curb. Only cells with a minimal number of updates are considered, because less updates means more noise. A Sobel operator is used for the edge detection an the result is normalized, if the normalized result finds itself within a range, then a road curb feature is found.

In the next step the features are registered in a second map with the size of the region of interest and a lower resolution.There must be a minimum of features in one of the low resolutions cells to be marked as a curb cell, because a road curb is not a singular feature like a reflector post used for road boundary detection. By building histograms of road curb features perpendicular to the driving direction the most probable path is determined. To build the polygonal chain the minimal distance approach is used,which considers the closest features to the most probable path as the road curb. In general the road curb is the closest boundary to the path visible in an elevation map. The output of the road curb detection algorithm are polygonal chains for both sides of the vehicle.


\subsection{Laserscanner Based Road Curb Detection}

In this section a method proposed in \cite{stereo} using a laser scanner to detect road curbs will be described. The argument for using laser scanners instead of stereo cameras is that the laserscanner provides more accurate data. Some methods have been developed, that use sensor fusion with the stereo camera to overcome this precision lacking. Unfortunately these methods produce a big overhead in the data processing step, which makes a big difference in an autonomous vehicle, because it is a real-time system.

For testing this method, the equipment proposed in \cite{stereo} is the following. For road curb detection, a multipurpose laserscanner is used. For the ego motion estimation a low cost inertial measurement unit is used in combination with the standard wheel speed sensors and chassis lift sensors. 

The road curb detection pipeline is shown in \ref{fig1}. As the figure shows, the detection is split into 3 modules. In the first module is used for for the road curb feature extraction and labelling. The detected road curb candidates have to be accumulated over time, so they are stored into the road curb map, where they undergo ego motion compensation. In the last module uses the temporal filtered parameters stored in the cells of the road curb map to group the road curb candidates into road curbs. In the end, the road curbs are represented as polygonal chains.  

\begin{figure}[ht]
	\centering
  %\includegraphics[scale = 0.5]{pictures/lidar_system.pdf}
  	\missingfigure{\Huge I need the image, now!}
	\caption{Ro}
	\label{fig1}
\end{figure}
  
At the point of detecting road curb features, three approaches can be used: segmentation using iterative end point fit and classification of segments, hierarchic segmentation and classification of segments, segmentation using regression lines and classification of segments.

The IEPF algorithm described in this section is a well known segmentation algorithm. In this method, the input to the algorithm is the orthogonal projections of the 3D points on the y-z plane. The start and end point of the scan line are connected and the distance to the straight line is calculated for each point, as shown in \ref{fig2}. The measurement points are split into two segments at the point with maximum distance, the circled point in \ref{fig2}, if it exceeds a predetermined threshold. This takes place for every generative segment iteratively, till there are no points that cross this threshold. For each segment that contains the minimum number of points, the angle $\alpha_S$ between the regression line of the segments, the average height and the variance of the height values is being calculated. The segments are classified into four classes: road curb, object, ground and street. This method assumes that the segments containing the central channels of the scan lines is a street. After that, the process continues by going in both direction of the scan line and classifying the object segment with a object classification algorithm. For the segments not labelled as objects, an angle between that segment and the last found street segment is calculated. If this angle $|\alpha - \alpha_S|$ is greater than a threshold $T_{\alpha,1}$, the segment is marked as a road curb. If the angle is greater than $T_{\alpha,2}$ but lower than $T_{\alpha,1}$, or the difference to the height of the neighboring lane segment $|h - h_S|$ is lower than $T_h$ or the difference in variance $|\sigma - \sigma_S|$ is above $T_\sigma$, then the segment is marked as ground. The variance criterion is used to distinguish the streets in unstructured environments, with a lot of gravel and grass for example. If none of these criteria are met, then the segment is classified as a street segment and is used for further evaluation of segments. 

\begin{figure}[ht]
	\centering
  %\includegraphics[scale = 0.35]{pictures/iepf.pdf}
    \missingfigure{\Huge I need the image, now!}
	\caption{Ro}
	\label{fig2}
\end{figure}
 

Another possible approach for segmentation is segmentation using regression lines. For every measurement point a forward and a backward regression line is calculated containing n points before or after the measurement point. The regression lines are calculated in the z-channel-space.  In all adjunct points with an intersection angle exceeding a certain threshold a maximum search regarding the intersection angle is conducted. At the maximum, a segment is terminated. The classification steps are performed in the y-z-space again as described for the IEPF algorithm. As the regressions lines are build with only a few measurement points this detection algorithm is sensitive to outliers int he data set? This segmentation method is shown in \ref{fig3}

\begin{figure}[ht]
	\centering
  %\includegraphics[scale = 0.5]{pictures/iepf2.pdf}
    \missingfigure{\Huge I need the image, now!}
	\caption{Ro}
	\label{fig3}
\end{figure}

The final segmentation method considered is the hieararchic segmentation and classification of segments. The segments are built pairwise from neighbouring height values. Two neighbouring segments are merged if the standard deviation of the height values in relation to the calculated regression line of the merged segment is below a certain threshold. This is processed in a pyramid procedure until a new segment does not fulfill the described variance criterion.This process is shown in \ref{fig4}

\begin{figure}[ht]
	\centering
 %\includegraphics[scale = 0.55]{pictures/iepf3.pdf}
   	\missingfigure{\Huge I need the image, now!}
	\caption{Ro}
	\label{fig4}
\end{figure}

The cells of the grid based road curb map contain a local description o the road curb based on a linear model. Each cell contains the model parameters center point $(x^C, y^C)$ and direction $d = (1, \beta_1)^T$, and additionally the number of cell updates n.The model parameters are updated with every curb feature lying in the cell. Of course this is not enough to achieve a precise road curb estimation so the centers of the road curbs are estimated within the cell.

The larger the cell is, the better the computation time and memory consumption. Large cells are good for straight road curbs, but smaller cells are better for road curbs with complex geometry.

For every new measurement frame an additional step is necessary to compensate the ego motion between two measurement time stamps(reference). 

The road curb extraction takes place in the road curb extraction module. The module uses the model parameters to build chains of road curb candidates. To identify the most relevant curb chains, an estimated central line of the current lane is used, as shown in \ref{fig5}



\begin{figure}[ht]
	\centering
  %\includegraphics[scale = 0.6]{pictures/extractor.pdf}
    \missingfigure{\Huge I need the image, now!}
	\caption{Ro}
	\label{fig5}
\end{figure}


The results obtained with this method are presented in \ref{tab1}.

\begin{table}[]
\centering
\caption{My caption}
\label{tab1}
\resizebox{\columnwidth}{20px}{\begin{tabular}{lllllll}
\cline{1-7}
\multicolumn{1}{|l|}{Methods} & \multicolumn{1}{l|}{Curb HR} & \multicolumn{1}{l|}{Curb FPR} & \multicolumn{1}{l|}{Object HR} & \multicolumn{1}{l|}{Object FPR} & \multicolumn{1}{l|}{Street HR} & \multicolumn{1}{l|}{Street FPR} \\ \cline{1-7} 
IEPF                         & 38.9\%                       & 3.3\%                         & 93.4\%                         & 0.9\%                           & 80.7\%                         & 12.9\%                          \\
Regression Lines             & 22.1\%                       & 1.5\%                         & 89.8\%                         & 0.9\%                           & 82.1\%                         & 19.6\%                          \\
Hierarchic Segmentation      & 30.9\%                       & 5.9\%                         & 73.2\%                         & 6.2\%                           & 78.2\%                         & 11.2\%                         
\end{tabular}}
\end{table}

The IEPF segmentation method has proven to be the most efficient method in detecting road curbs, with a slightly higher false positive rate than the regression lines method. Unfortunately the hierarchic segmentation method delivers the fastest result, this is the trade-off between speed and hit rate.


\section{Conclusion}
The conclusion goes here.
\nocite{*}

% use section* for acknowledgement
\section*{Acknowledgment}

The authors would like to thank...


\bibliographystyle{bibtex/IEEEtran}
\bibliography{bibliography}

% that's all folks
\end{document}


